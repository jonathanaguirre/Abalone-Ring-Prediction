{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "b99a33b7",
      "cell_type": "markdown",
      "source": "# Optimizing White Abalone Age Prediction\nThe white abalone (Haliotis sorenseni), is an endangered marine mollusk found along the Pacific coast of North America. The purpose of this experiment is to train multiple Machine Learning algorithms to predict ring count. From the abalone.csv file, three feature varibles and one Target variable will be utlized. Random Forest Regressor, Linear Regression, and XGBoost models will be used. ",
      "metadata": {}
    },
    {
      "id": "08e75d4e",
      "cell_type": "code",
      "source": "# Install and Import required packages and libraries. \n%pip install pandas matplotlib seaborn scikit-learn numpy xgboost optuna\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport optuna\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "id": "0b8b4e5b",
      "cell_type": "code",
      "source": "# Load the Abalone Dataset, display Column information, and then provide the first five rows.\nabalone_df = pd.read_csv('abalone.csv')\nabalone_df.info()\nabalone_df.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4177 entries, 0 to 4176\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   sex             4177 non-null   object \n 1   length          4177 non-null   float64\n 2   diameter        4177 non-null   float64\n 3   height          4177 non-null   float64\n 4   whole_weight    4177 non-null   float64\n 5   shucked_weight  4177 non-null   float64\n 6   viscera_weight  4177 non-null   float64\n 7   shell_weight    4177 non-null   float64\n 8   rings           4177 non-null   int64  \ndtypes: float64(7), int64(1), object(1)\nmemory usage: 277.4+ KB\n"
        },
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "  sex  length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n\n   shell_weight  rings  \n0         0.150     15  \n1         0.070      7  \n2         0.210      9  \n3         0.155     10  \n4         0.055      7  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex</th>\n      <th>length</th>\n      <th>diameter</th>\n      <th>height</th>\n      <th>whole_weight</th>\n      <th>shucked_weight</th>\n      <th>viscera_weight</th>\n      <th>shell_weight</th>\n      <th>rings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>0.455</td>\n      <td>0.365</td>\n      <td>0.095</td>\n      <td>0.5140</td>\n      <td>0.2245</td>\n      <td>0.1010</td>\n      <td>0.150</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>0.350</td>\n      <td>0.265</td>\n      <td>0.090</td>\n      <td>0.2255</td>\n      <td>0.0995</td>\n      <td>0.0485</td>\n      <td>0.070</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>0.530</td>\n      <td>0.420</td>\n      <td>0.135</td>\n      <td>0.6770</td>\n      <td>0.2565</td>\n      <td>0.1415</td>\n      <td>0.210</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>0.440</td>\n      <td>0.365</td>\n      <td>0.125</td>\n      <td>0.5160</td>\n      <td>0.2155</td>\n      <td>0.1140</td>\n      <td>0.155</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I</td>\n      <td>0.330</td>\n      <td>0.255</td>\n      <td>0.080</td>\n      <td>0.2050</td>\n      <td>0.0895</td>\n      <td>0.0395</td>\n      <td>0.055</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14
    },
    {
      "id": "4fccd52f-c444-403e-90d8-2609ff4708e0",
      "cell_type": "markdown",
      "source": "# Preprocessing Pipeline\nPredictor features (length, diameter, and height) for modeling are expanded upon using polynomial combinations (only interaction terms) and then scaled.",
      "metadata": {}
    },
    {
      "id": "2aa764e8",
      "cell_type": "code",
      "source": "# Predictor features are selected out of the nine avaible features.\nfeatures = ['length', 'diameter', 'height']\ntarget = 'rings'\n\n# Create polynominal combinations.\npoly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\nX_poly = poly.fit_transform(abalone_df[features])\n\n# Scale and transform polynominal combinations.\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_poly)\n\ny = abalone_df[target]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "id": "c2476201-d36d-4434-bee9-c51ba2f6b16f",
      "cell_type": "markdown",
      "source": "# Split the Data",
      "metadata": {}
    },
    {
      "id": "d3f292aa",
      "cell_type": "code",
      "source": "# Split data into training and testing sets.\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "id": "cb44df6f-6ddd-412d-81d8-431a233b49c2",
      "cell_type": "markdown",
      "source": "# Random Forest Regressor",
      "metadata": {}
    },
    {
      "id": "af55c7ac-d6a9-4b62-b968-831992c5f1d1",
      "cell_type": "markdown",
      "source": "## Hyperparameter Tuning and Optuna",
      "metadata": {}
    },
    {
      "id": "0bffc3d5",
      "cell_type": "code",
      "source": "# Hyperparameter tuning for Random Forest using Optuna.\ndef rf_objective(trial):\n    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n    max_depth = trial.suggest_int('max_depth', 2, 20)\n    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n    score = cross_val_score(rf, X_train, y_train, cv=5, scoring='r2').mean()\n    return score\n\n# Optuna creates and estimates the best parameters over twenty trials.\nstudy_rf = optuna.create_study(direction='maximize')\nstudy_rf.optimize(rf_objective, n_trials=20)\nrf_best_params = study_rf.best_params",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "[I 2025-03-20 15:06:14,795] A new study created in memory with name: no-name-89572b0e-3e4b-41f0-94dc-bb2dc7410693\n[I 2025-03-20 15:06:42,927] Trial 0 finished with value: 0.3692589290861622 and parameters: {'n_estimators': 240, 'max_depth': 8}. Best is trial 0 with value: 0.3692589290861622.\n[I 2025-03-20 15:07:03,828] Trial 1 finished with value: 0.36880519818739044 and parameters: {'n_estimators': 182, 'max_depth': 8}. Best is trial 0 with value: 0.3692589290861622.\n[I 2025-03-20 15:07:53,516] Trial 2 finished with value: 0.2675455687285755 and parameters: {'n_estimators': 276, 'max_depth': 17}. Best is trial 0 with value: 0.3692589290861622.\n[I 2025-03-20 15:08:16,125] Trial 3 finished with value: 0.2609383159259998 and parameters: {'n_estimators': 124, 'max_depth': 18}. Best is trial 0 with value: 0.3692589290861622.\n[I 2025-03-20 15:08:40,943] Trial 4 finished with value: 0.3576829169161101 and parameters: {'n_estimators': 195, 'max_depth': 9}. Best is trial 0 with value: 0.3692589290861622.\n[I 2025-03-20 15:08:49,332] Trial 5 finished with value: 0.32639724857998303 and parameters: {'n_estimators': 57, 'max_depth': 11}. Best is trial 0 with value: 0.3692589290861622.\n[I 2025-03-20 15:09:38,404] Trial 6 finished with value: 0.2818165128890775 and parameters: {'n_estimators': 286, 'max_depth': 15}. Best is trial 0 with value: 0.3692589290861622.\n[I 2025-03-20 15:09:48,039] Trial 7 finished with value: 0.3840704696450564 and parameters: {'n_estimators': 121, 'max_depth': 4}. Best is trial 7 with value: 0.3840704696450564.\n[I 2025-03-20 15:10:06,266] Trial 8 finished with value: 0.3841491926858897 and parameters: {'n_estimators': 187, 'max_depth': 6}. Best is trial 8 with value: 0.3841491926858897.\n[I 2025-03-20 15:10:53,881] Trial 9 finished with value: 0.26780643234277124 and parameters: {'n_estimators': 259, 'max_depth': 17}. Best is trial 8 with value: 0.3841491926858897.\n[I 2025-03-20 15:11:03,269] Trial 10 finished with value: 0.35875205571907665 and parameters: {'n_estimators': 131, 'max_depth': 2}. Best is trial 8 with value: 0.3841491926858897.\n[I 2025-03-20 15:11:11,044] Trial 11 finished with value: 0.3589402516899095 and parameters: {'n_estimators': 126, 'max_depth': 2}. Best is trial 8 with value: 0.3841491926858897.\n[I 2025-03-20 15:11:17,578] Trial 12 finished with value: 0.38652112614926243 and parameters: {'n_estimators': 74, 'max_depth': 5}. Best is trial 12 with value: 0.38652112614926243.\n[I 2025-03-20 15:11:22,767] Trial 13 finished with value: 0.3869514697351962 and parameters: {'n_estimators': 55, 'max_depth': 5}. Best is trial 13 with value: 0.3869514697351962.\n[I 2025-03-20 15:11:27,446] Trial 14 finished with value: 0.3873601559990165 and parameters: {'n_estimators': 51, 'max_depth': 5}. Best is trial 14 with value: 0.3873601559990165.\n[I 2025-03-20 15:11:41,078] Trial 15 finished with value: 0.3132346477869043 and parameters: {'n_estimators': 88, 'max_depth': 12}. Best is trial 14 with value: 0.3873601559990165.\n[I 2025-03-20 15:11:46,243] Trial 16 finished with value: 0.38402754671015793 and parameters: {'n_estimators': 52, 'max_depth': 6}. Best is trial 14 with value: 0.3873601559990165.\n[I 2025-03-20 15:12:00,644] Trial 17 finished with value: 0.3295521854819907 and parameters: {'n_estimators': 101, 'max_depth': 11}. Best is trial 14 with value: 0.3873601559990165.\n[I 2025-03-20 15:12:19,000] Trial 18 finished with value: 0.3838463305833625 and parameters: {'n_estimators': 221, 'max_depth': 4}. Best is trial 14 with value: 0.3873601559990165.\n[I 2025-03-20 15:12:45,674] Trial 19 finished with value: 0.2558269995949114 and parameters: {'n_estimators': 146, 'max_depth': 20}. Best is trial 14 with value: 0.3873601559990165.\n"
        }
      ],
      "execution_count": 17
    },
    {
      "id": "b8179a35-8d12-426d-a5d6-529f8b78da99",
      "cell_type": "markdown",
      "source": "## Train, Fit, Predict, Score",
      "metadata": {}
    },
    {
      "id": "1b040098",
      "cell_type": "code",
      "source": "# Train Optimized Random Forest model.\nrf = RandomForestRegressor(**rf_best_params, random_state=42)\n\n# Fit to traning data set.\nrf.fit(X_train, y_train)\n\n# Calculate predictions on test data set.\ny_pred_rf = rf.predict(X_test)\n\n# Score and calculate errors.\nrf_r2 = r2_score(y_test, y_pred_rf)\nrf_rmse = root_mean_squared_error(y_test, y_pred_rf)\nrf_mae = mean_absolute_error(y_test, y_pred_rf)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "id": "b5fa6372-5f52-4a3b-a50d-4012d3bb0279",
      "cell_type": "markdown",
      "source": "# XgBoost",
      "metadata": {}
    },
    {
      "id": "e71c10b6-0726-4b5f-a3fe-c3a92da848b7",
      "cell_type": "markdown",
      "source": "## Hyperparameter Tuning and Optuna",
      "metadata": {}
    },
    {
      "id": "20d0429f",
      "cell_type": "code",
      "source": "# Hyperparameter tuning for XGBoost using Optuna.\ndef xgb_objective(trial):\n    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n    max_depth = trial.suggest_int('max_depth', 2, 20)\n    xgb = XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n    score = cross_val_score(xgb, X_train, y_train, cv=5, scoring='r2').mean()\n    return score\n\n# Optuna creates and estimates the best parameters over twenty trials.\nstudy_xgb = optuna.create_study(direction='maximize')\nstudy_xgb.optimize(xgb_objective, n_trials=20)\nxgb_best_params = study_xgb.best_params",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "[I 2025-03-20 15:12:46,767] A new study created in memory with name: no-name-d587c44f-6d99-45ef-86ca-9bce7c22b6c5\n[I 2025-03-20 15:12:49,312] Trial 0 finished with value: 0.2947280764579773 and parameters: {'n_estimators': 213, 'learning_rate': 0.24570384162131917, 'max_depth': 3}. Best is trial 0 with value: 0.2947280764579773.\n[I 2025-03-20 15:13:14,378] Trial 1 finished with value: 0.04222288131713867 and parameters: {'n_estimators': 120, 'learning_rate': 0.28031723104656975, 'max_depth': 19}. Best is trial 0 with value: 0.2947280764579773.\n[I 2025-03-20 15:13:17,849] Trial 2 finished with value: 0.17820729017257692 and parameters: {'n_estimators': 217, 'learning_rate': 0.2814914348527951, 'max_depth': 5}. Best is trial 0 with value: 0.2947280764579773.\n[I 2025-03-20 15:13:37,511] Trial 3 finished with value: 0.08764967918395997 and parameters: {'n_estimators': 216, 'learning_rate': 0.2618701221794845, 'max_depth': 12}. Best is trial 0 with value: 0.2947280764579773.\n[I 2025-03-20 15:13:38,529] Trial 4 finished with value: 0.3524908423423767 and parameters: {'n_estimators': 153, 'learning_rate': 0.01052183691891083, 'max_depth': 2}. Best is trial 4 with value: 0.3524908423423767.\n[I 2025-03-20 15:13:39,854] Trial 5 finished with value: 0.37342233657836915 and parameters: {'n_estimators': 154, 'learning_rate': 0.05480383013216162, 'max_depth': 3}. Best is trial 5 with value: 0.37342233657836915.\n[I 2025-03-20 15:13:43,199] Trial 6 finished with value: 0.25001460313796997 and parameters: {'n_estimators': 159, 'learning_rate': 0.1368025133939711, 'max_depth': 6}. Best is trial 5 with value: 0.37342233657836915.\n[I 2025-03-20 15:13:50,924] Trial 7 finished with value: 0.09637174606323243 and parameters: {'n_estimators': 155, 'learning_rate': 0.2874014602135135, 'max_depth': 9}. Best is trial 5 with value: 0.37342233657836915.\n[I 2025-03-20 15:14:08,608] Trial 8 finished with value: 0.06921230554580689 and parameters: {'n_estimators': 157, 'learning_rate': 0.2746119263018004, 'max_depth': 13}. Best is trial 5 with value: 0.37342233657836915.\n[I 2025-03-20 15:14:10,823] Trial 9 finished with value: 0.3429186224937439 and parameters: {'n_estimators': 131, 'learning_rate': 0.07259388111597201, 'max_depth': 5}. Best is trial 5 with value: 0.37342233657836915.\n[I 2025-03-20 15:14:31,726] Trial 10 finished with value: 0.08375225067138672 and parameters: {'n_estimators': 72, 'learning_rate': 0.1334447954958459, 'max_depth': 16}. Best is trial 5 with value: 0.37342233657836915.\n[I 2025-03-20 15:14:34,161] Trial 11 finished with value: 0.38189263343811036 and parameters: {'n_estimators': 297, 'learning_rate': 0.013009706938982152, 'max_depth': 3}. Best is trial 11 with value: 0.38189263343811036.\n[I 2025-03-20 15:14:48,486] Trial 12 finished with value: 0.3365511894226074 and parameters: {'n_estimators': 300, 'learning_rate': 0.010705869558866016, 'max_depth': 8}. Best is trial 11 with value: 0.38189263343811036.\n[I 2025-03-20 15:14:59,674] Trial 13 finished with value: 0.20116066932678223 and parameters: {'n_estimators': 287, 'learning_rate': 0.07425701206604979, 'max_depth': 8}. Best is trial 11 with value: 0.38189263343811036.\n[I 2025-03-20 15:15:01,348] Trial 14 finished with value: 0.37259879112243655 and parameters: {'n_estimators': 253, 'learning_rate': 0.07775099788617461, 'max_depth': 2}. Best is trial 11 with value: 0.38189263343811036.\n[I 2025-03-20 15:15:02,956] Trial 15 finished with value: 0.30502010583877565 and parameters: {'n_estimators': 90, 'learning_rate': 0.19844606635258683, 'max_depth': 5}. Best is trial 11 with value: 0.38189263343811036.\n[I 2025-03-20 15:15:17,971] Trial 16 finished with value: 0.21411055326461792 and parameters: {'n_estimators': 193, 'learning_rate': 0.053331699875261714, 'max_depth': 10}. Best is trial 11 with value: 0.38189263343811036.\n[I 2025-03-20 15:16:05,455] Trial 17 finished with value: 0.10392614603042602 and parameters: {'n_estimators': 270, 'learning_rate': 0.04670863138356207, 'max_depth': 14}. Best is trial 11 with value: 0.38189263343811036.\n[I 2025-03-20 15:16:08,236] Trial 18 finished with value: 0.3116458296775818 and parameters: {'n_estimators': 248, 'learning_rate': 0.10989565604634913, 'max_depth': 4}. Best is trial 11 with value: 0.38189263343811036.\n[I 2025-03-20 15:16:10,567] Trial 19 finished with value: 0.27819554805755614 and parameters: {'n_estimators': 100, 'learning_rate': 0.1661208665173256, 'max_depth': 6}. Best is trial 11 with value: 0.38189263343811036.\n"
        }
      ],
      "execution_count": 19
    },
    {
      "id": "ba3edc8b-0b98-489d-af5e-803119756223",
      "cell_type": "markdown",
      "source": "## Train, Fit, Predict, Score",
      "metadata": {}
    },
    {
      "id": "53794c55",
      "cell_type": "code",
      "source": "# Train optimized XGBoost model.\nxgb = XGBRegressor(**xgb_best_params, random_state=42)\n\n# Fit to traning data set.\nxgb.fit(X_train, y_train)\n\n# Calculate predictions on test data set.\ny_pred_xgb = xgb.predict(X_test)\n\n# Score and calculate errors.\nxgb_r2 = r2_score(y_test, y_pred_xgb)\nxgb_rmse = root_mean_squared_error(y_test, y_pred_xgb)\nxgb_mae = mean_absolute_error(y_test, y_pred_xgb)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "id": "ca241d2a-3c7e-4d08-9716-628836964b06",
      "cell_type": "markdown",
      "source": "# Linear Regression",
      "metadata": {}
    },
    {
      "id": "ff6db093-6154-454b-abc5-340050f8a282",
      "cell_type": "markdown",
      "source": "## Train, Fit, Predict, Score",
      "metadata": {}
    },
    {
      "id": "cf22ccb8",
      "cell_type": "code",
      "source": "# Train optimized Linear Regression model with polynomial features.\nlr = LinearRegression()\n\n# Fit to training data set.\nlr.fit(X_train, y_train)\n\n# Calculate prediction on test data set.\ny_pred_lr = lr.predict(X_test)\n\n# Score and calculate errors.\nlr_r2 = r2_score(y_test, y_pred_lr)\nlr_rmse = root_mean_squared_error(y_test, y_pred_lr)\nlr_mae = mean_absolute_error(y_test, y_pred_lr)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "id": "c99be1d7-3ce2-449c-957a-1d7aebabf81c",
      "cell_type": "markdown",
      "source": "# Results",
      "metadata": {}
    },
    {
      "id": "f3d98f6e",
      "cell_type": "code",
      "source": "# Output results in a table. \nresults = pd.DataFrame({\n    'Model': ['Linear Regression', 'Random Forest', 'XGBoost'],\n    'R² Score': [lr_r2, rf_r2, xgb_r2],\n    'RMSE': [lr_rmse, rf_rmse, xgb_rmse],\n    'MAE': [lr_mae, rf_mae, xgb_mae]\n})\nprint(results)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "               Model  R² Score      RMSE       MAE\n0  Linear Regression  0.377189  2.596549  1.863254\n1      Random Forest  0.372607  2.606081  1.860613\n2            XGBoost  0.380125  2.590419  1.846835\n"
        }
      ],
      "execution_count": 22
    }
  ]
}